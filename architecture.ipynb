{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing required packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting cuda device is available\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32    # batch size : number of sentences in a batcgh\n",
    "seq_len = 128      # sequence length : number of tokens(words) in a sentence\n",
    "num_embd = 384     # num ebmedding : embedding dimension for a single token\n",
    "num_heads = 2      # num heads : number of multihead attention for encoder and decoder blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading file for extracting sentences to make a corpus\n",
    "\n",
    "with open('001ssb.txt', 'r') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].replace(' \\n', '')\n",
    "    corpus[i] = corpus[i].replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting words(tokens) from the courpus\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for sent in corpus:\n",
    "    for word in sent.split():\n",
    "        tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only first 50000 tokens from then corpus\n",
    "\n",
    "tokens = tokens[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating embeddings from the above formed tokens\n",
    "\n",
    "def get_embeddings(words, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    \n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    \n",
    "    batch_size = 32\n",
    "    for i in range(0, len(words), batch_size):\n",
    "        batch = words[i:i + batch_size]\n",
    "        \n",
    "        \n",
    "        encoded = tokenizer(batch, \n",
    "                          padding=True, \n",
    "                          truncation=True,\n",
    "                          max_length=128,\n",
    "                          return_tensors='pt')\n",
    "        \n",
    "        \n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded)\n",
    "            \n",
    "        \n",
    "        attention_mask = encoded['attention_mask']\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sentence_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        \n",
    "       \n",
    "        embeddings.append(sentence_embeddings.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    all_embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(tokens)    # embeddings shape : (50000, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embeddings   # storing the embeddings to a varaiable for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encodings\n",
    "\n",
    "def POS_Emb():\n",
    "    pos_emb = torch.empty(seq_len, num_embd)\n",
    "\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(num_embd):\n",
    "            if i % 2 == 0:\n",
    "                emb = math.sin(pos / (10000 ** ((2 * i)/num_embd)))\n",
    "            else:\n",
    "                emb = math.cos(pos / (10000 ** ((2 * (i - 1))/num_embd)))\n",
    "\n",
    "            t_emb = torch.tensor(emb)\n",
    "            pos_emb[pos][i] = t_emb\n",
    "\n",
    "    out = pos_emb\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = POS_Emb()\n",
    "pe = pe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__();\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.wq = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wk = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wv = nn.Linear(num_embd, head_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.wq(x)\n",
    "        k = self.wk(x)\n",
    "        v = self.wv(x)\n",
    "\n",
    "        energy = torch.matmul(q, k.transpose(-2, -1)) * (self.head_size ** -0.5)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([EncoderHead(head_size) for _ in range(num_heads)])\n",
    "        self.wo = nn.Linear(num_heads * head_size, num_embd, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "        out = self.wo(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, num_features),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        head_size = num_embd // num_heads\n",
    "        self.mha = EncoderMultiHeadAttention(num_heads, head_size)\n",
    "        self.ffwd = EncoderFeedForward(num_embd)\n",
    "        self.ln1 = nn.LayerNorm(num_embd)\n",
    "        self.ln2 = nn.LayerNorm(num_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.ln1(self.mha(x))\n",
    "        x = x + self.ln2(self.ffwd(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            EncoderBlock(num_heads),\n",
    "            EncoderBlock(num_heads),\n",
    "            EncoderBlock(num_heads),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + pe[:x.shape[1], :]\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.wq = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wk = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wv = nn.Linear(num_embd, head_size, bias=False)\n",
    "\n",
    "    def forward(self, x, l):\n",
    "\n",
    "        q = self.wq(l)\n",
    "        k = self.wk(x)\n",
    "        v = self.wv(x)\n",
    "\n",
    "        energy = torch.matmul(q, k.transpose(-2, -1)) * (self.head_size ** -0.5)\n",
    "\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossMultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([CrossHead(head_size) for _ in range(num_heads)])\n",
    "        self.wo = nn.Linear(head_size * num_heads, num_embd, bias=False)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "\n",
    "        out = torch.cat([h(x, l) for h in self.heads], dim=-1)\n",
    "\n",
    "        out = self.wo(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.wq = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wk = nn.Linear(num_embd, head_size, bias=False)\n",
    "        self.wv = nn.Linear(num_embd, head_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.wq(x)\n",
    "        k = self.wk(x)\n",
    "        v = self.wv(x)\n",
    "\n",
    "        energy = torch.matmul(q, k.transpose(-2, -1)) * (self.head_size ** -0.5)\n",
    "        energy = torch.tril(energy)\n",
    "        energy = energy.masked_fill(energy==0, float('-inf'))\n",
    "         \n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "\n",
    "        out = torch.matmul(attention, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderMultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([DecoderHead(head_size) for _ in range(num_heads)])\n",
    "        self.wo = nn.Linear(head_size * num_heads, num_embd, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "        out = self.wo(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, num_embd):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_embd, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, num_embd),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.model(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        head_size = num_embd // num_heads\n",
    "        self.mmha = DecoderMultiHeadAttention(num_heads, head_size)\n",
    "        self.ln1 = nn.LayerNorm(num_embd)\n",
    "        self.ffwd = DecoderFeedForward(num_embd)\n",
    "        self.ln2 = nn.LayerNorm(num_embd)\n",
    "        self.cmha = CrossMultiheadAttention(num_heads, head_size)\n",
    "        self.ln3 = nn.LayerNorm(num_embd)\n",
    "\n",
    "    def forward(self, x, l):\n",
    "\n",
    "        x = x + self.ln1(self.mmha(x))\n",
    "        x = x + self.ln2(self.cmha(x, l))\n",
    "        x = x + self.ln3(self.ffwd(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DecoderBlock(num_heads),\n",
    "            DecoderBlock(num_heads),\n",
    "            DecoderBlock(num_heads),\n",
    "        ])\n",
    "        self.linear = nn.Linear(num_embd, vocab_size)\n",
    "\n",
    "    def forward(self, x, l, action):\n",
    "\n",
    "        x = x + pe[:x.shape[1], :]\n",
    "        for block in self.blocks:\n",
    "            x = block(x, l)\n",
    "\n",
    "        if action == 'train':\n",
    "            x = self.linear(x)\n",
    "\n",
    "        if action == 'inference':\n",
    "            x = self.linear(x[:, -1, :])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDatasetLoader(x):\n",
    "\n",
    "    data = []\n",
    "    total_batches = x.shape[0] // (batch_size * seq_len)\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        b = []\n",
    "        for bs in range(batch_size):\n",
    "            batch = []\n",
    "            for sl in range(seq_len * bs + (batch_size * seq_len * batch_idx), (seq_len * bs) + (batch_size * seq_len * batch_idx) + seq_len):\n",
    "                    batch.append(x[sl])\n",
    "\n",
    "            b.append(batch)\n",
    "        data.append(b)\n",
    "\n",
    "    return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyborg\\AppData\\Local\\Temp\\ipykernel_15672\\1584269112.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  return torch.tensor(data)\n"
     ]
    }
   ],
   "source": [
    "data_loader = customDatasetLoader(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_heads)\n",
    "        self.decoder = Decoder(num_heads, vocab_size=batch_size * seq_len * len(data_loader))\n",
    "\n",
    "    def forward(self, x, l=None, action='train'):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x, l, action)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25168560"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params    # total parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configs\n",
    "\n",
    "epochs = 70\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating targets for evaluating loss\n",
    "\n",
    "def generateTargets(x):\n",
    "\n",
    "    data = []\n",
    "    total_batches = x.shape[0] // (batch_size * seq_len)\n",
    "\n",
    "    for batch in range(total_batches):\n",
    "        b = []\n",
    "        for bs in range(batch_size):\n",
    "            batch = []\n",
    "            for sl in range(seq_len * bs + 1, (seq_len * bs) + seq_len):\n",
    "                    batch.append(torch.tensor())\n",
    "\n",
    "            b.append(batch)\n",
    "        data.append(b)\n",
    "\n",
    "    return torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.arange(0, 32 * 128 * 12).reshape(12, 32, 128)\n",
    "base_sequence = torch.ones(32 * 128, dtype=torch.int).reshape(32, 128)\n",
    "targets = base_sequence + targets\n",
    "targets[-1][-1][-1] -= torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating labels for training the model\n",
    "\n",
    "def generateLabels(x):\n",
    "    data = []\n",
    "    total_batches = x.shape[0] // (batch_size * seq_len)\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        b = []\n",
    "        for bs in range(batch_size):\n",
    "            batch_start = (batch_idx * batch_size + bs) * seq_len + 1\n",
    "            batch_end = batch_start + seq_len\n",
    "            batch = x[batch_start:batch_end]\n",
    "\n",
    "            b.append(batch)\n",
    "        data.append(b)\n",
    "\n",
    "    return torch.tensor(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = generateLabels(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 13.718318939208984\n",
      "Epoch : 10, Loss : 7.884413242340088\n",
      "Epoch : 20, Loss : 5.46866512298584\n",
      "Epoch : 30, Loss : 4.171416282653809\n",
      "Epoch : 40, Loss : 3.2255072593688965\n",
      "Epoch : 50, Loss : 2.592472791671753\n",
      "Epoch : 60, Loss : 1.796868085861206\n",
      "Loss : 1.736008644104004\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # forward pass\n",
    "    result = model(data_loader[0], labels[0], 'train')\n",
    "\n",
    "    # calculate loss\n",
    "    loss = loss_fn(result.view(-1, batch_size * seq_len * len(data_loader)), targets[0].view(-1))\n",
    "\n",
    "    # zero grads\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update params\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch : {epoch}, Loss : {loss}\")\n",
    "\n",
    "print(f\"Loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inputs(size):\n",
    "    inputs = torch.ones([1, size, num_embd])\n",
    "    \n",
    "    for i in range(size):\n",
    "        inputs[0, i] = data_loader[0][0][i]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(size, ls, output):\n",
    "    els = torch.ones([1, size+1, num_embd])\n",
    "\n",
    "    for i in range(size):\n",
    "        els[0, i] = ls[0, i]\n",
    "\n",
    "    els[0, size] = torch.tensor(embeddings[torch.argmax(output)])\n",
    "\n",
    "    return els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepening Of Thrones Book One before, A Night's of Ice and he he George R. R. Martin PROLOGUE \"We should start back,\" Gared urged to the means began to north, dark around them. \"The wildlings are dead.\" \"Do the dead frighten you?\" Ser Waymar Royce asked with all the nameless of a tree, Gared muttered. not rise to forest. moon can blades the old man, past fifty, and hard arm. seen the lordlings come and go. \"Dead not dead,\" he grizzled \"We have felt business with the top \"Are they dead?\" Royce asked softly. \"What proof have we?\" \"Will saw them,\" Gared said. \"If he says they are dead, that's proof enough for me.\" Will had no they would drag him into the position sooner or later. He "
     ]
    }
   ],
   "source": [
    "ls = torch.ones([1, 1, 384])\n",
    "ls[0, 0] = labels[0, 0, 0]\n",
    "\n",
    "for i in range(128):\n",
    "    inputs = make_inputs(i+1)\n",
    "\n",
    "    output = model(inputs, ls, 'inference')\n",
    "    print(tokens[torch.argmax(output)], end=\" \")\n",
    "    ls = make_labels(i+1, ls, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
